# ============================================================================
# JUNJO SERVER - PRODUCTION VM DEPLOYMENT
# ============================================================================
# This docker-compose configuration includes all required Junjo service
# containers, as well as a Caddy reverse proxy container to route
# web traffic to the appropriate container.
# ============================================================================

services:
  # The sample junjo sdk powered app that sends telemetry
  junjo-app:
    build: ./junjo_app
    container_name: junjo-app
    restart: unless-stopped
    networks:
      - junjo-network
    env_file:
      - .env
    depends_on:
      - junjo-server-ingestion

  # Junjo AI Studio Services
  junjo-ai-studio-backend:
    image: mdrideout/junjo-ai-studio-backend:0.70.3
    container_name: junjo-ai-studio-backend
    restart: unless-stopped
    volumes:
      # Database storage (required for all modes)
      - ${JUNJO_HOST_DB_DATA_PATH:-./.dbdata}:/app/.dbdata
    ports:
      - "1323:1323" # HTTP API (public)
    networks:
      - junjo-network
    env_file:
      - .env
    environment:
      # Override host/port for Docker network communication
      - INGESTION_HOST=junjo-ai-studio-ingestion
      - INGESTION_PORT=50052
      # Enable migrations on startup
      - RUN_MIGRATIONS=true
      # Database paths (hardcoded for Docker, users configure host mount via JUNJO_HOST_DB_DATA_PATH)
      - JUNJO_SQLITE_PATH=/app/.dbdata/sqlite/junjo.db
      - JUNJO_DUCKDB_PATH=/app/.dbdata/duckdb/traces.duckdb

  junjo-ai-studio-ingestion:
    image: mdrideout/junjo-ai-studio-ingestion:0.70.3
    container_name: junjo-ai-studio-ingestion
    restart: unless-stopped
    volumes:
      # Database storage (required for all modes)
      - ${JUNJO_HOST_DB_DATA_PATH:-./.dbdata}:/app/.dbdata
    ports:
      - "50051:50051" # Public OTLP endpoint (authenticated via API key)
    networks:
      - junjo-network
    env_file:
      - .env
    environment:
      - BACKEND_GRPC_HOST=junjo-ai-studio-backend
      - BACKEND_GRPC_PORT=50053
      # Database path (hardcoded for Docker, users configure host mount via JUNJO_HOST_DB_DATA_PATH)
      - JUNJO_BADGERDB_PATH=/app/.dbdata/badgerdb
    depends_on:
      junjo-ai-studio-backend:
        condition: service_started
    healthcheck:
      test: ["CMD", "grpc_health_probe", "-addr=localhost:50052"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s

  junjo-ai-studio-frontend:
    image: mdrideout/junjo-ai-studio-frontend:0.70.3
    container_name: junjo-ai-studio-frontend
    restart: unless-stopped
    ports:
      - "5153:80" # Public frontend (production build - nginx serving static files on port 80)
    env_file:
      - .env
    networks:
      - junjo-network
    depends_on:
      junjo-ai-studio-backend:
        condition: service_started

  # Caddy Reverse Proxy (internet traffic routing to Junjo AI Studio services)
  caddy:
    build:
      context: ./caddy
    container_name: junjo-caddy
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - "80:80" # For HTTP -> HTTPS redirect
      - "443:443" # For HTTPS
      - "443:443/udp" # For HTTP/3
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile # Mount your Caddyfile
      - caddy_data:/data # Persist Caddy data (certificates)
    networks:
      - junjo-network
    depends_on:
      - junjo-ai-studio-backend
      - junjo-ai-studio-frontend

volumes:
  caddy_data: # Persistent Caddy data (SSL certificates, configuration)

networks:
  junjo-network:
    name: junjo_network
    driver: bridge
